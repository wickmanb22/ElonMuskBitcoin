# Remove punctuations
TextDoc <- tm_map(TextDoc, removePunctuation)
# Eliminate extra white spaces
TextDoc <- tm_map(TextDoc, stripWhitespace)
# Text stemming - which reduces words to their root form
TextDoc <- tm_map(TextDoc, stemDocument)
# Save
satoshi_clean_list[[k]] <- TextDoc
}
musk_clean_list <- list()
for (k in 1:length(musk_list)) {
#Replacing "/", "@" and "|" with space
TextDoc <- tm_map(musk_list[[k]], toSpace, "/")
TextDoc <- tm_map(TextDoc, toSpace, "@")
TextDoc <- tm_map(TextDoc, toSpace, "\\|")
# Convert the text to lower case
TextDoc <- tm_map(TextDoc, content_transformer(tolower))
# Remove numbers
TextDoc <- tm_map(TextDoc, removeNumbers)
# Remove the word "page"
TextDoc <- tm_map(TextDoc, removeWords, c("page"))
# Remove punctuations
TextDoc <- tm_map(TextDoc, removePunctuation)
# Eliminate extra white spaces
TextDoc <- tm_map(TextDoc, stripWhitespace)
# Text stemming - which reduces words to their root form
TextDoc <- tm_map(TextDoc, stemDocument)
# Save
musk_clean_list[[k]] <- TextDoc
}
View(satoshi_clean_list)
View(musk_clean_list)
musk_word_freq <- list()
for (l in 1:length(musk_clean_list)) {
TextDoc_dtm <- TermDocumentMatrix(musk_clean_list[[l]])
dtm_m <- as.matrix(TextDoc_dtm)
# Sort by descearing value of frequency
dtm_v <- sort(rowSums(dtm_m),decreasing=TRUE)
musk_word_freq[[l]] <- data.frame(word = names(dtm_v),freq=dtm_v) %>%
mutate(total_words = sum(freq),
per1000 = freq * (1000/total_words)) %>%
filter(word %in% stopwords("english"))
}
View(musk_word_freq)
satoshi_word_freq <- list()
for (l in 1:length(satoshi_clean_list)) {
TextDoc_dtm <- TermDocumentMatrix(satoshi_clean_list[[l]])
dtm_m <- as.matrix(TextDoc_dtm)
# Sort by descearing value of frequency
dtm_v <- sort(rowSums(dtm_m),decreasing=TRUE)
satoshi_word_freq[[l]] <- data.frame(word = names(dtm_v),freq=dtm_v) %>%
mutate(total_words = sum(freq),
per1000 = freq * (1000/total_words)) %>%
filter(word %in% stopwords("english"))
}
View(satoshi_word_freq)
satoshi_df <- rbindlist(satoshi_word_freq, idcol = "sample")%>%
complete(sample, word)
# Fill in total_words
filler_df_satoshi <- satoshi_df %>% distinct(sample, total_words) %>% drop_na()
satoshi_df1 <- satoshi_df %>%
left_join(filler_df_satoshi, by = "sample") %>%
select(-total_words.x) %>%
rename(total_words = total_words.y) %>%
replace(is.na(.), 0)
# Include unused words (0 counts are important)
musk_df <- rbindlist(musk_word_freq, idcol = "sample")%>%
complete(sample, word)
# Fill in total_words
filler_df_msuk <- musk_df %>% distinct(sample, total_words) %>% drop_na()
musk_df1 <- musk_df %>%
left_join(filler_df_musk, by = "sample") %>%
select(-total_words.x) %>%
rename(total_words = total_words.y) %>%
replace(is.na(.), 0)
# Fill in total_words
filler_df_musk <- musk_df %>% distinct(sample, total_words) %>% drop_na()
musk_df1 <- musk_df %>%
left_join(filler_df_musk, by = "sample") %>%
select(-total_words.x) %>%
rename(total_words = total_words.y) %>%
replace(is.na(.), 0)
View(musk_df1)
# Include unused words (0 counts are important)
satoshi_df <- rbindlist(satoshi_word_freq, idcol = "sample")%>%
complete(sample, word)
# Fill in total_words
filler_df_satoshi <- satoshi_df %>% distinct(sample, total_words) %>% drop_na()
satoshi_df1 <- satoshi_df %>%
left_join(filler_df_satoshi, by = "sample") %>%
select(-total_words.x) %>%
rename(total_words = total_words.y) %>%
replace(is.na(.), 0) %>%
mutate(author == "satoshi")
# Include unused words (0 counts are important)
musk_df <- rbindlist(musk_word_freq, idcol = "sample")%>%
complete(sample, word)
# Fill in total_words
filler_df_musk <- musk_df %>% distinct(sample, total_words) %>% drop_na()
musk_df1 <- musk_df %>%
left_join(filler_df_musk, by = "sample") %>%
select(-total_words.x) %>%
rename(total_words = total_words.y) %>%
replace(is.na(.), 0) %>%
mutate(author == "musk")
musk_df1 <- musk_df %>%
left_join(filler_df_musk, by = "sample") %>%
select(-total_words.x) %>%
rename(total_words = total_words.y) %>%
replace(is.na(.), 0) %>%
mutate(author = "musk")
satoshi_df1 <- satoshi_df %>%
left_join(filler_df_satoshi, by = "sample") %>%
select(-total_words.x) %>%
rename(total_words = total_words.y) %>%
replace(is.na(.), 0) %>%
mutate(author = "satoshi")
View(musk_df1)
# Combine dataframes
clean_df <- cbind(satoshi_df1, musk_df1)
# Combine dataframes
clean_df <- rbind(satoshi_df1, musk_df1)
View(clean_df)
# Distribution of word counts
satoshi_df1 %>%
distinct(sample, total_words) %>%
filter(total_words < 2000) %>%
ggplot() +
geom_density(aes(total_words, color = author, fill = author), alpha = 0.6) +
theme_clean() +
labs(
title = "Word Counts of Satoshi's 50 blog posts",
caption = "Excludes the Bitcoin Whitepaper (>2000 words)"
)
# Distribution of word counts
clean_df %>%
distinct(sample, total_words) %>%
filter(total_words < 2000) %>%
ggplot() +
geom_density(aes(total_words, color = author, fill = author), alpha = 0.6) +
theme_clean() +
labs(
title = "Word Counts of Satoshi's 50 blog posts",
caption = "Excludes the Bitcoin Whitepaper (>2000 words)"
)
# Distribution of word counts
clean_df %>%
distinct(sample, author, total_words) %>%
filter(total_words < 2000) %>%
ggplot() +
geom_density(aes(total_words, color = author, fill = author), alpha = 0.6) +
theme_clean() +
labs(
title = "Word Counts of Satoshi's 50 blog posts",
caption = "Excludes the Bitcoin Whitepaper (>2000 words)"
)
# Distribution of word counts
clean_df %>%
distinct(sample, author, total_words) %>%
#filter(total_words < 2000) %>%
ggplot() +
geom_density(aes(total_words, color = author, fill = author), alpha = 0.6) +
theme_clean() +
labs(
title = "Word Counts of Satoshi's 50 blog posts",
caption = "Excludes the Bitcoin Whitepaper (>2000 words)"
)
# Distribution of word counts
clean_df %>%
distinct(sample, author, total_words) %>%
filter(total_words < 2000) %>%
ggplot() +
geom_density(aes(total_words, color = author, fill = author), alpha = 0.6) +
theme_clean() +
labs(
title = "Word Counts of Satoshi's 50 blog posts",
caption = "Excludes the Bitcoin Whitepaper (>2000 words)"
)
# Most popular stopwords
clean_df %>%
group_by(author, word) %>%
summarise(total_usage = sum(freq)) %>%
arrange(desc(total_usage))
clean_df %>%
filter(word == "the" | word == "that" | word == "and" | word == "for" | word == "you") %>%
ggplot() +
geom_density(aes(per1000, group = word, color = word, fill = word), alpha = 0.3) +
theme_clean() +
labs(
title = "Rates of Use of Satoshi's Most Frequent Words"
)
# rates of the most popular words
clean_df %>%
filter(author == "satashi", word == "the" | word == "that" | word == "and" | word == "for" | word == "you") %>%
ggplot() +
geom_density(aes(per1000, group = word, color = word, fill = word), alpha = 0.3) +
theme_clean() +
labs(
title = "Rates of Use of Satoshi's Most Frequent Words"
)
# rates of the most popular words
clean_df %>%
filter(author == "satoshi", word == "the" | word == "that" | word == "and" | word == "for" | word == "you") %>%
ggplot() +
geom_density(aes(per1000, group = word, color = word, fill = word), alpha = 0.3) +
theme_clean() +
labs(
title = "Rates of Use of Satoshi's Most Frequent Words"
)
# Book graphic #1
clean_df %>%
mutate(author = as.factor(author)) %>%
filter(word == "the") %>%
ggplot() %>%
geom_point(aes(x = per1000, y = author))
# Book graphic #1
clean_df %>%
mutate(author = as.factor(author)) %>%
filter(word == "the") %>%
ggplot() +
geom_point(aes(x = per1000, y = author))
# Book graphic #1
clean_df %>%
mutate(author = as.factor(author)) %>%
filter(word == "the") %>%
ggplot() +
geom_jitter(aes(x = per1000, y = author))
# Book graphic #1
clean_df %>%
mutate(author = as.factor(author)) %>%
filter(word == "the") %>%
ggplot() +
geom_jitter(aes(x = per1000, y = author), color = blue)
# Book graphic #1
clean_df %>%
mutate(author = as.factor(author)) %>%
filter(word == "the") %>%
ggplot() +
geom_jitter(aes(x = per1000, y = author), color = "blue")
# Book graphic #1
clean_df %>%
mutate(author = as.factor(author)) %>%
filter(word == "the") %>%
ggplot() +
geom_jitter(aes(x = per1000, y = author), color = "blue") +
labs(
x = "Rate per 1000 words",
y = "Authorship",
title = "Observed rates of the word 'the'"
)
# Book graphic #1
clean_df %>%
mutate(author = as.factor(author)) %>%
filter(word == "the") %>%
ggplot() +
geom_jitter(aes(x = per1000, y = author), color = "blue", height = 0.25) +
labs(
x = "Rate per 1000 words",
y = "Authorship",
title = "Observed usage rates of the word 'the'"
)
# Book graphic #1
clean_df %>%
mutate(author = as.factor(author)) %>%
filter(word == "the") %>%
ggplot() +
geom_jitter(aes(x = per1000, y = author), color = "blue", height = 0.2) +
labs(
x = "Rate per 1000 words",
y = "Authorship",
title = "Observed usage rates of the word 'the'"
)
# Book graphic #1
clean_df %>%
mutate(author = as.factor(author)) %>%
filter(word == "the") %>%
ggplot() +
geom_jitter(aes(x = per1000, y = author), color = "blue", height = 0.15) +
labs(
x = "Rate per 1000 words",
y = "Authorship",
title = "Observed usage rates of the word 'the'"
)
# Book graphic #1
clean_df %>%
mutate(author = as.factor(author)) %>%
filter(word == "the") %>%
ggplot() +
geom_jitter(aes(x = per1000, y = author), color = "royalblue", height = 0.15) +
labs(
x = "Rate per 1000 words",
y = "Authorship",
title = "Observed usage rates of the word 'the'"
)
# Book graphic #1
clean_df %>%
mutate(author = as.factor(author)) %>%
filter(word == "the") %>%
ggplot() +
geom_jitter(aes(x = per1000, y = author), color = "blue", height = 0.15) +
labs(
x = "Rate per 1000 words",
y = "Authorship",
title = "Observed usage rates of the word 'the'"
)
# Book graphic #1
clean_df %>%
mutate(author = as.factor(author)) %>%
filter(word == "the") %>%
ggplot() +
geom_jitter(aes(x = per1000, y = author), color = "royalblue", height = 0.2) +
labs(
x = "Rate per 1000 words",
y = "Authorship",
title = "Observed usage rates of the word 'the'"
)
clean_df %>%
group_by(author, word) %>%
summarise(total_usage = sum(freq)) %>%
arrange(desc(total_usage))
# Book graphic #1
clean_df %>%
mutate(author = as.factor(author)) %>%
filter(word == "that") %>%
ggplot() +
geom_jitter(aes(x = per1000, y = author), color = "royalblue", height = 0.2) +
labs(
x = "Rate per 1000 words",
y = "Authorship",
title = "Observed usage rates of the word 'the'"
)
# Book graphic #1
clean_df %>%
mutate(author = as.factor(author)) %>%
filter(word == "that") %>%
ggplot() +
geom_jitter(aes(x = per1000, y = author), color = "royalblue", height = 0.2) +
labs(
x = "Rate per 1000 words",
y = "Authorship",
title = "Observed usage rates of the word 'and'"
)
# Book graphic #1
clean_df %>%
mutate(author = as.factor(author)) %>%
filter(word == "that") %>%
ggplot() +
geom_jitter(aes(x = per1000, y = author), color = "royalblue", height = 0.2) +
labs(
x = "Rate per 1000 words",
y = "Authorship",
title = "Observed usage rates of the word 'you'"
)
# Book graphic #1
clean_df %>%
mutate(author = as.factor(author)) %>%
filter(word == "that") %>%
ggplot() +
geom_jitter(aes(x = per1000, y = author), color = "royalblue", height = 0.2) +
labs(
x = "Rate per 1000 words",
y = "Authorship",
title = "Observed usage rates of the word 'would'"
)
# Book graphic #1
clean_df %>%
mutate(author = as.factor(author)) %>%
filter(word == "and") %>%
ggplot() +
geom_jitter(aes(x = per1000, y = author), color = "royalblue", height = 0.2) +
labs(
x = "Rate per 1000 words",
y = "Authorship",
title = "Observed usage rates of the word 'would'"
)
# Book graphic #1
clean_df %>%
mutate(author = as.factor(author)) %>%
filter(word == "would") %>%
ggplot() +
geom_jitter(aes(x = per1000, y = author), color = "royalblue", height = 0.2) +
labs(
x = "Rate per 1000 words",
y = "Authorship",
title = "Observed usage rates of the word 'would'"
)
clean_df %>%
+       group_by(author, word) %>%
+       summarise(total_usage = sum(freq)) %>%
+       arrange(desc(total_usage))
clean_df %>%
group_by(author, word) %>%
summarise(total_usage = sum(freq)) %>%
arrange(desc(total_usage))
print(n = 20)
clean_df %>%
group_by(author, word) %>%
summarise(total_usage = sum(freq)) %>%
arrange(desc(total_usage)) %>%
head(20)
# Book graphic #1
clean_df %>%
mutate(author = as.factor(author)) %>%
filter(word == "for") %>%
ggplot() +
geom_jitter(aes(x = per1000, y = author), color = "royalblue", height = 0.2) +
labs(
x = "Rate per 1000 words",
y = "Authorship",
title = "Observed usage rates of the word 'would'"
)
install.packages("rjags")
library(rjags)
remove.packages("rjags")
install.packages("rjags")
library(rjags)
# Bayesian Models
# Model 1
modelString = "
model {
## sampling
for (i in 1:N) {
y[i] ~ dpois(n[i] * lambda / 1000)
}
## prior
lambda ~ dgamma(0.001, 0.001)
}
"
clean_df %>%
mutate(author = as.factor(author)) %>%
filter(word == "for") %>%
ggplot() +
geom_jitter(aes(x = per1000, y = author), color = "royalblue", height = 0.2) +
labs(
x = "Rate per 1000 words",
y = "Authorship",
title = "Observed usage rates of the word 'would'"
)
# Book graphic #1
clean_df %>%
mutate(author = as.factor(author)) %>%
filter(word == "that") %>%
ggplot() +
geom_jitter(aes(x = per1000, y = author), color = "royalblue", height = 0.2) +
labs(
x = "Rate per 1000 words",
y = "Authorship",
title = "Observed usage rates of the word 'would'"
)
# Book graphic #1
clean_df %>%
mutate(author = as.factor(author)) %>%
filter(word == "and") %>%
ggplot() +
geom_jitter(aes(x = per1000, y = author), color = "royalblue", height = 0.2) +
labs(
x = "Rate per 1000 words",
y = "Authorship",
title = "Observed usage rates of the word 'would'"
)
# Book graphic #1
clean_df %>%
mutate(author = as.factor(author)) %>%
filter(word == "and") %>%
ggplot() +
geom_jitter(aes(x = per1000, y = author), color = "royalblue", height = 0.2) +
labs(
x = "Rate per 1000 words",
y = "Authorship",
title = "Observed usage rates of the word 'and'"
)
# Bayesian Models
# Define data
m1_and <- clean_df %>%
filter(word == "and")
View(m1_and)
y <- m1_and$per1000
N <- length(y)
the_data <- list("y" = y,
"N" = N)
View(the_data)
the_data <- list("y" = y,
"N" = N,
"a" = 0.001,
"b" = 0.001)
# Run the model
posterior <- run.jags(modelString,
n.chains = 1,
data = the_data,
monitor = "lambda",
adapt = 1000,
burnin = 5000,
sample = 5000)
library(rjags)
# Run the model
posterior <- run.jags(modelString,
n.chains = 1,
data = the_data,
monitor = "lambda",
adapt = 1000,
burnin = 5000,
sample = 5000)
library(rjags)
# Run the model
posterior <- run.jags(modelString,
n.chains = 1,
data = the_data,
monitor = "lambda",
adapt = 1000,
burnin = 5000,
sample = 5000)
remove.packages("rjags")
